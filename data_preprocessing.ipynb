{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: https://archive.ics.uci.edu/dataset/186/wine+quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_red = pd.read_csv(\"data/winequality-red.csv\", sep=\";\")\n",
    "df_white = pd.read_csv(\"data/winequality-white.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data catenation\n",
    "Those data have one cathegorical variable _type_. As there are two .csv files, one for each variable, it is neccessary to transform two files without _type_ variable to one table with new column(s) to capture the new variable _type_. Because there is just one cathegorical variable which has only two values, the transformation could be done using on-hot trick without significant size/dimension affection of the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new on-hot columns to each dataset\n",
    "df_red[\"red\"] = 1\n",
    "df_red[\"white\"] = 0\n",
    "\n",
    "df_white[\"red\"] = 0\n",
    "df_white[\"white\"] = 1\n",
    "\n",
    "# catenate both datasets together\n",
    "df = pd.concat([df_red, df_white], ignore_index=True)\n",
    "\n",
    "# catenation were successful, column names and row count as expected\n",
    "# print(df.info())\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing\n",
    "There are a lot of data preprocessing methods which should be used in ussual case. But in this dataset, a lot of potentional problems cannot occur. There is not any _date_ variable, neither _strings_ or other objects. Using the _info()_ method of pandas dataframe, we can see that the dataset has none of _None_ or _NAN_ values, so all are presented, and there are also just _int_ or _float_ variables. Moreover, all columns have same number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed acidity           0\n",
      "volatile acidity        0\n",
      "citric acid             0\n",
      "residual sugar          0\n",
      "chlorides               0\n",
      "free sulfur dioxide     0\n",
      "total sulfur dioxide    0\n",
      "density                 0\n",
      "pH                      0\n",
      "sulphates               0\n",
      "alcohol                 0\n",
      "quality                 0\n",
      "red                     0\n",
      "white                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# there is not any None value in any column\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 14)\n",
      "(5320, 14)\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unite units\n",
    "Those two columns contains values in mg/dm3 instead of g/dm3. Thus, those are converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"free sulfur dioxide\"] = df[\"free sulfur dioxide\"] / 1000\n",
    "df[\"total sulfur dioxide\"] = df[\"total sulfur dioxide\"] / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize the features\n",
    "For the predicted value _quality_ and the integer/bool values of _red_ and _white_ it does not make any sense to do the standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "features = df.drop(columns=[\"quality\", \"red\", \"white\"]).columns\n",
    "scaler = StandardScaler()\n",
    "df[features] = scaler.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the features\n",
    "Normalisation of all columns, except the quality, where we need the original values. The normalisation of _red_ and _white_ column does nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features and target variable to the range [0, 1]\n",
    "# print(df.describe())\n",
    "features = df.drop(columns=[\"quality\"]).columns\n",
    "scaler = MinMaxScaler()\n",
    "df[features] = scaler.fit_transform(df[features])\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outliers detection\n",
    "We tried z-score and IQR to detect and get rid of outliers. Since the IQR perform better, we chose it for the final use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outliers\n",
    "outliers = ((df < (Q1 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "\n",
    "# Remove outliers\n",
    "df = df[~outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put wine quality as a final column\n",
    "cols = list(df.columns)\n",
    "cols[-3], cols[-1] = cols[-1], cols[-3]\n",
    "df = df[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/wine_prepared.csv\", index=False)    # ignore indices while saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
